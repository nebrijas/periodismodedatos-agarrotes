{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154dfb9a",
   "metadata": {},
   "source": [
    "# Práctica de Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcd842",
   "metadata": {},
   "source": [
    "En esta actividad dirigida importaremos de la edición digital del diario español [El País](https://elpais.com/ \"El País\") la tabla de [El medallero de Tokio 2020](https://resultados.elpais.com/deportivos/juegos-olimpicos/medallero/ \"Tabla Tokio 2020\")\n",
    "\n",
    "Los pasos que se seguirán en este código serán los siguientes:\n",
    "1. Importar librerías\n",
    "2. Variables\n",
    "3. Hacemos la pregunta\n",
    "4. Bucle para obtener los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa6daf",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1a3ab",
   "metadata": {},
   "source": [
    "En primer lugar haremos uso de la librería [requests](https://docs.python-requests.org/en/latest/ \"requests\") para bajarnos la página web desde la que queremos obtener y descargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4661b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a28929",
   "metadata": {},
   "source": [
    " Tras ello, importaremos la segunda librería llamada [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/ \"bs4\") con el objetivo de analizar los datos que ya nos hemos descargado en el paso previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "239cde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fdd2b",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a96a2",
   "metadata": {},
   "source": [
    "Explicación de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c199b4",
   "metadata": {},
   "source": [
    "### Definimos URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f5b2b",
   "metadata": {},
   "source": [
    "En este paso, lo primero que debemos hacer es definir la [URL](https://resultados.elpais.com/deportivos/juegos-olimpicos/medallero/ \"Tabla Tokio 2020\") en la que queremos hacer web scraping y obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be8787c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://resultados.elpais.com/deportivos/juegos-olimpicos/medallero/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be41e7",
   "metadata": {},
   "source": [
    "### Realizamos la petición a la web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f79257",
   "metadata": {},
   "source": [
    "Después, a través de la orden ```req = requests.get(URL)``` realizamos la petición a la web, en caso de que la página no pueda ser leída, es decir, que sea ```req.status_code != 200``` el código imprimirá \"No se puede hacer Web Scraping en [URL](https://resultados.elpais.com/deportivos/juegos-olimpicos/medallero/ \"URL\"). En cambio, si conseguimos obtener los datos de esta página, es decir, siempre y cuando sea ```req.status_code == 200```, el código imprimirá \"Vamos a por ello\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42938e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos a por ello\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(URL)\n",
    "if (req.status_code != 200):\n",
    "    raise Exception(\"No se puede hacer Web Scraping en\"+ URL)\n",
    "if (req.status_code == 200):\n",
    "    print(\"Vamos a por ello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a144626",
   "metadata": {},
   "source": [
    "### De resquests a BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51e82a",
   "metadata": {},
   "source": [
    "Tras el paso anterior, lo siguiente será pasar el contenido HTML de la web a un objeto [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/ \"bs4\") a través de la orden ```html = BeautifulSoup(req.text, \"html.parser\")```. Esto quiere decir, que Beautiful Soup es una librería Python que permite extraer información de contenido en [formato HTML o XML](https://j2logo.com/python/web-scraping-con-python-guia-inicio-beautifulsoup/ \"Web scraping con Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30578d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(req.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa41f6f",
   "metadata": {},
   "source": [
    "### Variables de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7001e4c",
   "metadata": {},
   "source": [
    "En este apartado, lo que hacemos es definir las variables paises, oros, platas, bronces y totales; y después las identificamos con la función ```find_all()``` que sirve para obtener todas las etiquetas que cumplan con las condiciones del objeto HTML y después, tras obtenerlas, esta función se encarga de devolverlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00f38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "  paises = html.find_all(\"th\",{\"class\":\"pais\"})\n",
    "  oros = html.find_all(\"td\",{\"class\":\"m_oro\"})\n",
    "  platas = html.find_all(\"td\",{\"class\":\"m_plata\"})\n",
    "  bronces = html.find_all(\"td\",{\"class\":\"m_bronce\"})\n",
    "  totales = html.find_all(\"td\",{\"class\":\"m_total\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365a9d5",
   "metadata": {},
   "source": [
    "## Hacemos la pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62083760",
   "metadata": {},
   "source": [
    "En este siguiente paso, realizamos la siguiente pregunta a quién este haciendo uso del código: **\"¿QUIERES CONOCER LOS 20 PAÍSES QUE HAN OBTENIDO MÁS MEDALLAS EN 2020?\"**. En el caso de que la persona pulse la tecla **s**, entonces significará que sí quiere conocer estos datos, por lo que el código imprimirá \"De acuerdo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac5813ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿QUIERES CONOCER LOS 20 PAÍSES QUE HAN OBTENIDO MÁS MEDALLAS EN 2020?\n",
      " \n",
      " Si tu respuesta es Sí, presiona \"s\" \n",
      "s\n",
      "\n",
      "De acuerdo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "respuesta=input('¿QUIERES CONOCER LOS 20 PAÍSES QUE HAN OBTENIDO MÁS MEDALLAS EN 2020?\\n \\n Si tu respuesta es Sí, presiona \"s\" \\n')\n",
    "if(respuesta == 's'): \n",
    "    print('\\nDe acuerdo\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d8adf",
   "metadata": {},
   "source": [
    "## Bucle para obtener los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9bec6d",
   "metadata": {},
   "source": [
    "Finalmente, con el objetivo de obtener los datos, realizaremos un bucle for, es decir, repetiremos el bloque de instrucciones un total de 20 veces, ya que estas iteraciones han sido determinadas previamente a través de la orden ```for i in range (20):```. En este caso, una vez se haya realizado el bucle, el código imprimirá ```%d``` que hace referencia a los números del ranking y la ```%s``` que se utiliza para dar formato a las cadenas de texto. Ambos valores se asocian a través de una tupla utilizando el operador %. Además, la orden ```[i+1]``` se utiliza para que el bucle vaya corriendo y no se quede estancado en ningún valor hasta que bucle finalice y se rompa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRESULTADOS DE LOS DATOS DE LOS JUEGOS OLÍMPICOS 2020\\n')\n",
    "print ('PAÍSES')\n",
    "\n",
    "for i in range (20):\n",
    "    # Con el método \"getText()\" no nos devuelve el HTML\n",
    "    print(\"%d. %s \\nOro: %s Plata: %s Bronce: %s \\n Total: %s \\n \" % (i+1, paises[i+1].text.strip(),oros[i].text.strip(),platas[i].text.strip(),bronces[i].text.strip(), totales[i].text.strip()))\n",
    "\n",
    "else:\n",
    "  print('Qué lástima, y...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797199b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
